{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uWIp0075Okf"
      },
      "source": [
        "# Fine-tuning 5th. Workflow (2nd + Ï∫êÍ∏Ä noraml dataset + ai-hub 12000Ïû• damaged Ï†ÅÏö©)\n",
        "1. ÌïòÏù¥Î∏åÎ¶¨Îìú ÎùºÎ≤®ÎßÅ Ï†ÑÎûµ (Hybrid Labeling Strategy)\n",
        "    - 1Îã®Í≥Ñ (Ïö∞ÏÑ†ÏàúÏúÑ): Auto-Labeling (YOLOv8x)\n",
        "        - ÏùºÎã® Pre-trained Î™®Îç∏Î°ú \"Ï∞®Îüâ Ï†ÑÏ≤¥ ÌòïÏÉÅ\"ÏùÑ Ï∞æÍ∏∞\n",
        "        - ÏÑ±Í≥µ Ïãú: Normal Îç∞Ïù¥ÌÑ∞ÏôÄ Í∏∞Ï§ÄÏù¥ Í∞ôÏïÑÏßÄÎØÄÎ°ú Î≤†Ïä§Ìä∏\n",
        "    - 2Îã®Í≥Ñ (Fallback): JSON ÎùºÎ≤® ÌôúÏö©\n",
        "        - ÎßåÏïΩ Î™®Îç∏Ïù¥ ÎÑàÎ¨¥ ÌôïÎåÄÎêú(Zoom-in) Ïù¥ÎØ∏ÏßÄÎùº Ï∞®ÎüâÏùÑ Î™ª Ï∞æÏúºÎ©¥(Empty), Í∑∏Îïå JSONÏùò ÌååÏÜê Î∂ÄÏúÑ Ï¢åÌëúÎ•º Í∞ÄÏ†∏Ïò¥\n",
        "    - Ïù¥Ïú†: \"Î™ª Ï∞æÏïòÎã§Í≥† Îπà ÌååÏùº(Background)\"Î°ú ÎëêÎ©¥ Ïïà Îê©ÎãàÎã§. Damaged Ìè¥ÎçîÏóê ÏûàÏúºÎØÄÎ°ú Î¨¥Ï°∞Í±¥. Î∂ÄÎ∂ÑÎßåÏù¥ÎùºÎèÑ 'Ï∞®Îüâ'Ïù¥ÎùºÍ≥† Í∞ÄÎ•¥Ï≥êÏïº\n",
        "\n",
        "2. Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† Î∞è Í≤©Î¶¨\n",
        " - Î™®Îç∏Ïùò ÏïîÍ∏∞(Memorizing)Î•º Î∞©ÏßÄÌïòÍ≥† Í∞ùÍ¥ÄÏ†ÅÏù∏ ÏÑ±Îä• Í≤ÄÏ¶ùÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨.\n",
        " - ÎπÑÏú® (Ratio): Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î•º 7 : 2 : 1 ÎπÑÏú®Î°ú ÎûúÎç§ Î∂ÑÌï†.\n",
        "    - Train (70%): Î™®Îç∏ Í∞ÄÏ§ëÏπò ÏóÖÎç∞Ïù¥Ìä∏Ïö© (ÌïôÏäµ).\n",
        "    - Val (20%): ÌïôÏäµ Ï§ë ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ Î∞è Ï°∞Í∏∞ Ï¢ÖÎ£å(Early Stopping) Í≤∞Ï†ïÏö©.\n",
        "    - Test (10%): ÏôÑÏ†Ñ Í≤©Î¶¨(Isolation). ÌïôÏäµ Í≥ºÏ†ïÏóê Ï†àÎåÄ Í¥ÄÏó¨ÌïòÏßÄ ÏïäÏúºÎ©∞, ÏµúÏ¢Ö ÏÑ±Îä• ÌèâÍ∞ÄÏóêÎßå ÏÇ¨Ïö©.\n",
        "\n",
        "3. ÌïôÏäµ ÌôòÍ≤Ω ÏÑ§Ï†ï (Configuration)\n",
        " - YOLO Î™®Îç∏Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò ÏúÑÏπòÏôÄ ÌÅ¥ÎûòÏä§ Ï†ïÎ≥¥Î•º Ïïå Ïàò ÏûàÎèÑÎ°ù ÏÑ§Ï†ï.\n",
        " - yolov8_tuning_251207.yaml ÏÉùÏÑ±: Train/Val Í≤ΩÎ°ú Î∞è ÌÅ¥ÎûòÏä§Î™Ö(Vehicle) Ï†ïÏùò (Test Í≤ΩÎ°ú Ï†úÏô∏)\n",
        " - Hyperparameter:\n",
        "    - Freeze: Pre-trained Í∞ÄÏ§ëÏπò ÏïûÎã®ÏùÑ Í≥†Ï†ïÌïòÏó¨ Í∏∞Ï°¥Ïùò ÏùºÎ∞òÏ†ÅÏù∏ ÌäπÏßï Ï∂îÏ∂ú Îä•Î†• Ïú†ÏßÄ.\n",
        "    - Epochs: 15~20Ìöå (Í≥ºÏ†ÅÌï© Î∞©ÏßÄÎ•º ÏúÑÌï¥ Ï†ÅÏ†àÌïú ÌöüÏàò ÏÑ§Ï†ï).\n",
        "    - Learning Rate: ÎØ∏ÏÑ∏ Ï°∞Ï†ïÏùÑ ÏúÑÌï¥ ÎÇÆÏùÄ ÌïôÏäµÎ•† Ï†ÅÏö©.\n",
        "\n",
        "4. ÌïôÏäµ ÏàòÌñâ (Fine-tuning Execution)\n",
        " - Ï§ÄÎπÑÎêú Îç∞Ïù¥ÌÑ∞(Train/Val)Î•º ÌÜµÌï¥ Î™®Îç∏Ïù¥ ÏÉàÎ°úÏö¥ ÎèÑÎ©îÏù∏(ÌååÏÜê, Ï§åÏù∏ Ïù¥ÎØ∏ÏßÄ) Ï†ÅÏùë.\n",
        " - process\n",
        "    - Pre-trained yolov8x.pt Î°úÎìú.\n",
        "    - ÏÜêÏã§ Ìï®Ïàò(Loss Function)Í∞Ä ÏµúÏÜåÌôîÎêòÎäî Î∞©Ìñ•ÏúºÎ°ú Í∞ÄÏ§ëÏπò ÏóÖÎç∞Ïù¥Ìä∏.\n",
        "    - Í≤∞Í≥ºÎ¨º: Ïö∞Î¶¨ Îç∞Ïù¥ÌÑ∞Ïóê ÏµúÏ†ÅÌôîÎêú best.pt Î™®Îç∏ ÏÉùÏÑ±\n",
        "\n",
        " 5. ÏµúÏ¢Ö ÏÑ±Îä• ÌèâÍ∞Ä (Final Evaluation)\n",
        " - ÌïôÏäµÏóê ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÏùÄ Test SetÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïã§Ï†Ñ ÏÑ±Îä• Í≤ÄÏ¶ù.\n",
        " - Í≤ÄÏ¶ù Î∞©Î≤ï\n",
        "    - Í≤©Î¶¨Ìï¥Îëî Test Set(10%)Ïóê ÎåÄÌï¥ Ï∂îÎ°† ÏàòÌñâ.\n",
        "    - Í∏∞Ï°¥ Pre-trained Î™®Îç∏ ÎåÄÎπÑ False Negative(ÎØ∏Í≤ÄÏ∂ú) Í∞êÏÜåÎüâ ÌôïÏù∏.\n",
        "    - Ï£ºÏöî ÏßÄÌëú: Accuracy(Ï†ïÌôïÎèÑ), Recall(Ïû¨ÌòÑÏú®), Confusion Matrix(ÌòºÎèô ÌñâÎ†¨) ÎπÑÍµê Î∂ÑÏÑù.\n",
        " 6. (Ï∂îÍ∞Ä) damaged ÌååÏùº Ï∂îÍ∞Ä\n",
        "  - (Í∏∞Ï°¥) Í∏∞Ï°¥ ai-hub ÏÉòÌîå 1200Ïû• damaged ÌååÏùº\n",
        "  - (Í∞úÏÑ†) ai-hub ÏõêÎ≥∏ 50ÎßåÏû•ÏóêÏÑú ÌååÏÜê Ï¢ÖÎ•ò(4)Ïóê Îî∞Îùº ÎèôÏùºÌïú ÎπÑÏú®Î°ú 12000Ïû• Ï†ÅÏö©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2-e3-P3Of7a"
      },
      "source": [
        "# ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOGE-DmT1CjC"
      },
      "outputs": [],
      "source": [
        "# [Cell 1] ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "# YOLOv8 Î∞è Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨Ïóê ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
        "!pip install ultralytics tqdm\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import random\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "# Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ ÌôòÍ≤Ω ÏÑ§Ï†ï ÏôÑÎ£å\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FelueqD6OqiD"
      },
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï Î∞è Î∂ÑÌï† 1Ï∞®\n",
        " - Ï∫êÍ∏Ä Îç∞Ïù¥ÌÑ∞ÏÖã Ï∂îÍ∞Ä + ai-hub 12000Ïû• damaged ÌååÏùº\n",
        " - confidence threshold 0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (Source)\n",
        "# (1) AI-Hub (Damaged)\n",
        "AI_HUB_IMG_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/images\"\n",
        "AI_HUB_LBL_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/labels\"\n",
        "\n",
        "# (2) Normal & Background (Source Base)\n",
        "NORMAL_ROOT_BASE = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/RAW\"\n",
        "\n",
        "# 2. Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÄÏû• Í≤ΩÎ°ú (Destination)\n",
        "DEST_DIR = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\""
      ],
      "metadata": {
        "id": "ZoExzU9sXdwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Î∞òÎ≥µ Ïã§Ìñâ Í∏àÏßÄ(x)"
      ],
      "metadata": {
        "id": "_2-AalN03z94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 1] (ÏàòÏ†ïÎ≥∏) ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è ÌïòÏù¥Î∏åÎ¶¨Îìú Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï\n",
        "# ÏàòÏ†ï ÏÇ¨Ìï≠: background Ìè¥Îçî Ï∂îÍ∞Ä Î∞è 'empty' Ï†ÑÎûµ Ï†ÅÏö©\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏ (Ïù¥ÎØ∏ ÎêòÏñ¥ ÏûàÏúºÎ©¥ Í±¥ÎÑàÎúÄ)\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# ==============================================================================\n",
        "# ‚öôÔ∏è [ÏÑ§Ï†ï] Í≤ΩÎ°ú Î∞è ÌååÎùºÎØ∏ÌÑ∞ Ï†ïÏùò\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (Source)\n",
        "# (1) AI-Hub (Damaged)\n",
        "AI_HUB_IMG_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/images\"\n",
        "AI_HUB_LBL_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/labels\"\n",
        "\n",
        "# (2) Normal & Background (Source Base)\n",
        "NORMAL_ROOT_BASE = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/RAW\"\n",
        "\n",
        "# 2. Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÄÏû• Í≤ΩÎ°ú (Destination)\n",
        "DEST_DIR = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "\n",
        "# 3. Î™®Îç∏ ÏÑ§Ï†ï (Auto-LabelingÏö©)\n",
        "AUTO_LABEL_MODEL = 'yolov8x.pt'\n",
        "\n",
        "# 4. Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† ÎπÑÏú®\n",
        "SPLIT_RATIO = {'train': 0.7, 'val': 0.2, 'test': 0.1}\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def setup_directories():\n",
        "    \"\"\"Ï†ÄÏû•ÏÜå Ìè¥Îçî Íµ¨Ï°∞ Ï¥àÍ∏∞Ìôî\"\"\"\n",
        "    if os.path.exists(DEST_DIR):\n",
        "        print(f\"‚ö†Ô∏è Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã Ìè¥ÎçîÍ∞Ä Ï°¥Ïû¨Ìï©ÎãàÎã§. ÏÇ≠Ï†ú ÌõÑ Ïû¨ÏÉùÏÑ±Ìï©ÎãàÎã§: {DEST_DIR}\")\n",
        "        shutil.rmtree(DEST_DIR)\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(DEST_DIR, 'images', split), exist_ok=True)\n",
        "        os.makedirs(os.path.join(DEST_DIR, 'labels', split), exist_ok=True)\n",
        "    print(f\"‚úÖ Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ± ÏôÑÎ£å\")\n",
        "\n",
        "def get_target_image_paths():\n",
        "    \"\"\"ÎåÄÏÉÅ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú ÏàòÏßë (Background Ìè¨Ìï®)\"\"\"\n",
        "    print(\"üîç Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú ÏàòÏßë Ï§ë...\")\n",
        "\n",
        "    # 1. AI-Hub Images (Damaged)\n",
        "    damaged_imgs = glob.glob(os.path.join(AI_HUB_IMG_ROOT, \"**\", \"*.jpg\"), recursive=True)\n",
        "    damaged_imgs += glob.glob(os.path.join(AI_HUB_IMG_ROOT, \"**\", \"*.png\"), recursive=True)\n",
        "\n",
        "    # 2. Normal & Background Images (ÏßÄÏ†ïÎêú 3Í∞ú Ìè¥Îçî)\n",
        "    # [ÏàòÏ†ï] background Ìè¥Îçî Ï∂îÍ∞Ä\n",
        "    target_folders = ['normal', 'normal(kaggle_dataset)', 'background']\n",
        "    normal_bg_imgs = []\n",
        "\n",
        "    for folder_name in target_folders:\n",
        "        folder_path = os.path.join(NORMAL_ROOT_BASE, folder_name)\n",
        "        if os.path.exists(folder_path):\n",
        "            imgs = glob.glob(os.path.join(folder_path, \"**\", \"*.jpg\"), recursive=True)\n",
        "            imgs += glob.glob(os.path.join(folder_path, \"**\", \"*.png\"), recursive=True)\n",
        "            print(f\"   üëâ Folder '{folder_name}': {len(imgs)}Ïû•\")\n",
        "            normal_bg_imgs += imgs\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è Í≤ΩÍ≥†: Ìè¥ÎçîÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {folder_path}\")\n",
        "\n",
        "    print(f\"   -------------------------------------------\")\n",
        "    print(f\"   ‚úÖ AI-Hub (Damaged): {len(damaged_imgs)}Ïû•\")\n",
        "    print(f\"   ‚úÖ Normal/Background: {len(normal_bg_imgs)}Ïû•\")\n",
        "    print(f\"   -------------------------------------------\")\n",
        "\n",
        "    all_imgs = damaged_imgs + normal_bg_imgs\n",
        "    random.shuffle(all_imgs)\n",
        "    return all_imgs\n",
        "\n",
        "def get_fallback_label_from_txt(img_path):\n",
        "    \"\"\"[Fallback] AI-Hub Îç∞Ïù¥ÌÑ∞Ïù∏ Í≤ΩÏö∞, Í∏∞Ï°¥ TXT ÎùºÎ≤®ÏùÑ Ï∞æÏïÑ '0' ÌÅ¥ÎûòÏä§Î°ú Î≥ÄÌôò Î∞òÌôò\"\"\"\n",
        "    file_name = os.path.basename(img_path)\n",
        "    txt_name = os.path.splitext(file_name)[0] + \".txt\"\n",
        "\n",
        "    # Í≤ΩÎ°ú Îß§Ïπ≠ Î∞è Í≤ÄÏÉâ\n",
        "    try:\n",
        "        rel_path = os.path.relpath(os.path.dirname(img_path), AI_HUB_IMG_ROOT)\n",
        "        target_txt_path = os.path.join(AI_HUB_LBL_ROOT, rel_path, txt_name)\n",
        "    except:\n",
        "        target_txt_path = \"\"\n",
        "\n",
        "    if not os.path.exists(target_txt_path):\n",
        "        found = glob.glob(os.path.join(AI_HUB_LBL_ROOT, \"**\", txt_name), recursive=True)\n",
        "        if found: target_txt_path = found[0]\n",
        "        else: return None\n",
        "\n",
        "    try:\n",
        "        with open(target_txt_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        new_lines = []\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                # ÌÅ¥ÎûòÏä§ ID -> '0' (Vehicle)\n",
        "                new_line = f\"0 {parts[1]} {parts[2]} {parts[3]} {parts[4]}\"\n",
        "                new_lines.append(new_line)\n",
        "        return new_lines if new_lines else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def run_hybrid_labeling(img_paths):\n",
        "    print(f\"üöÄ Hybrid Labeling ÏãúÏûë (Ï¥ù {len(img_paths)}Ïû•)...\")\n",
        "    print(\"   (Strategies: damaged=hybrid, normal=auto, background=empty)\")\n",
        "\n",
        "    model = YOLO(AUTO_LABEL_MODEL)\n",
        "    stats = {'auto': 0, 'fallback': 0, 'bg': 0, 'skip': 0,\n",
        "             'train': 0, 'val': 0, 'test': 0}\n",
        "\n",
        "    for img_path in tqdm(img_paths):\n",
        "        label_data = []\n",
        "\n",
        "        # Í≤ΩÎ°ú Î∂ÑÏÑùÏúºÎ°ú ÏÜåÏä§ ÌåêÎ≥Ñ\n",
        "        # Ï£ºÏùò: Ìè¥ÎçîÎ™Ö Îß§Ïπ≠ Ïãú os.sep(/)ÏùÑ Ìè¨Ìï®ÌïòÍ±∞ÎÇò splitÌï¥ÏÑú Ï†ïÌôïÌûà ÎπÑÍµê\n",
        "        path_parts = img_path.split(os.sep)\n",
        "\n",
        "        # [ÏàòÏ†ï] Ï†ÑÎûµ Î∂ÑÍ∏∞\n",
        "        if 'background' in path_parts:\n",
        "            # Ï†ÑÎûµ: \"empty\" (Í∞ïÏ†ú Î∞∞Í≤Ω Ï≤òÎ¶¨)\n",
        "            # YOLO ÎèåÎ¶¨ÏßÄ ÏïäÍ≥† Î∞îÎ°ú Îπà ÎùºÎ≤® ÏÉùÏÑ±\n",
        "            label_data = []\n",
        "            stats['bg'] += 1\n",
        "\n",
        "        elif ('normal' in path_parts) or ('normal(kaggle_dataset)' in path_parts):\n",
        "            # Ï†ÑÎûµ: \"auto_label\" (Normal)\n",
        "            # YOLOÎ°ú Ï∞® Ï∞æÍ∏∞ -> ÏóÜÏúºÎ©¥ Background(empty)\n",
        "            results = model.predict(source=img_path, conf=0.5, classes=[2, 5, 7], verbose=False)\n",
        "            if len(results[0].boxes) > 0:\n",
        "                for box in results[0].boxes:\n",
        "                    x, y, w, h = box.xywhn[0].tolist()\n",
        "                    label_data.append(f\"0 {x:.6f} {y:.6f} {w:.6f} {h:.6f}\")\n",
        "                stats['auto'] += 1\n",
        "            else:\n",
        "                label_data = [] # Î™ª Ï∞æÏúºÎ©¥ Î∞∞Í≤ΩÏúºÎ°ú ÌôúÏö©\n",
        "                stats['bg'] += 1\n",
        "\n",
        "        else:\n",
        "            # Ï†ÑÎûµ: \"hybrid\" (AI-Hub Damaged)\n",
        "            # 1. Auto-Labeling ÏãúÎèÑ\n",
        "            results = model.predict(source=img_path, conf=0.5, classes=[2, 5, 7], verbose=False)\n",
        "            if len(results[0].boxes) > 0:\n",
        "                for box in results[0].boxes:\n",
        "                    x, y, w, h = box.xywhn[0].tolist()\n",
        "                    label_data.append(f\"0 {x:.6f} {y:.6f} {w:.6f} {h:.6f}\")\n",
        "                stats['auto'] += 1\n",
        "            else:\n",
        "                # 2. Fallback (Í∏∞Ï°¥ TXT)\n",
        "                fallback_lines = get_fallback_label_from_txt(img_path)\n",
        "                if fallback_lines:\n",
        "                    label_data = fallback_lines\n",
        "                    stats['fallback'] += 1\n",
        "                else:\n",
        "                    stats['skip'] += 1\n",
        "                    continue\n",
        "\n",
        "        # --- Î∂ÑÌï† Î∞è Ï†ÄÏû• ---\n",
        "        rand = random.random()\n",
        "        if rand < SPLIT_RATIO['train']: split = 'train'\n",
        "        elif rand < SPLIT_RATIO['train'] + SPLIT_RATIO['val']: split = 'val'\n",
        "        else: split = 'test'\n",
        "\n",
        "        file_name = os.path.basename(img_path)\n",
        "        shutil.copy2(img_path, os.path.join(DEST_DIR, 'images', split, file_name))\n",
        "\n",
        "        txt_name = os.path.splitext(file_name)[0] + \".txt\"\n",
        "        with open(os.path.join(DEST_DIR, 'labels', split, txt_name), 'w') as f:\n",
        "            if label_data:\n",
        "                f.write(\"\\n\".join(label_data))\n",
        "        stats[split] += 1\n",
        "\n",
        "    print(\"\\n‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ï ÏôÑÎ£å!\")\n",
        "    print(f\"   [Labeling] Auto: {stats['auto']} | Fallback: {stats['fallback']} | BG(Empty): {stats['bg']} | Skip: {stats['skip']}\")\n",
        "    print(f\"   [Split] Train: {stats['train']} | Val: {stats['val']} | Test: {stats['test']}\")\n",
        "\n",
        "def create_yaml():\n",
        "    yaml_txt = f\"\"\"\n",
        "    path: {DEST_DIR}\n",
        "    train: images/train\n",
        "    val: images/val\n",
        "    test: images/test\n",
        "    names:\n",
        "      0: Vehicle\n",
        "    \"\"\"\n",
        "    path = os.path.join(DEST_DIR, 'data.yaml')\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(yaml_txt)\n",
        "    print(f\"‚úÖ YAML ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: {path}\")\n",
        "    return path\n",
        "\n",
        "# --- Ïã§Ìñâ ---\n",
        "setup_directories()\n",
        "target_images = get_target_image_paths()\n",
        "run_hybrid_labeling(target_images)\n",
        "YAML_PATH_GENERATED = create_yaml()"
      ],
      "metadata": {
        "id": "ooz2G-kxQCrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQK9ENyyOvXk"
      },
      "outputs": [],
      "source": [
        "# [Cell 2] Îç∞Ïù¥ÌÑ∞ÏÖã ÌòÑÌô© Í≤ÄÏ¶ù (Verification)\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def print_dataset_stats(base_dir):\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üìä [Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ÄÏ¶ù Î¶¨Ìè¨Ìä∏] : {base_dir}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    splits = ['train', 'val', 'test']\n",
        "    total_imgs = 0\n",
        "    total_lbls = 0\n",
        "    total_bg = 0\n",
        "\n",
        "    for split in splits:\n",
        "        img_dir = os.path.join(base_dir, 'images', split)\n",
        "        lbl_dir = os.path.join(base_dir, 'labels', split)\n",
        "\n",
        "        # ÌååÏùº Í∞úÏàò ÌôïÏù∏\n",
        "        n_imgs = len(glob.glob(os.path.join(img_dir, \"*.*\")))\n",
        "        txt_files = glob.glob(os.path.join(lbl_dir, \"*.txt\"))\n",
        "        n_lbls = len(txt_files)\n",
        "\n",
        "        # Îπà ÎùºÎ≤® ÌååÏùº(Background) ÌôïÏù∏\n",
        "        n_empty_lbls = 0\n",
        "        for txt in txt_files:\n",
        "            if os.path.getsize(txt) == 0:\n",
        "                n_empty_lbls += 1\n",
        "\n",
        "        print(f\"üìÇ [{split.upper()}]\")\n",
        "        print(f\"   - Images : {n_imgs}Ïû•\")\n",
        "        print(f\"   - Labels : {n_lbls}Í∞ú\")\n",
        "        print(f\"     „Ñ¥ Ïú†Ìö® ÎùºÎ≤®(Vehicle) : {n_lbls - n_empty_lbls}Í∞ú\")\n",
        "        print(f\"     „Ñ¥ Îπà ÎùºÎ≤®(Background): {n_empty_lbls}Í∞ú (Ïò§ÌÉêÏßÄ Î∞©ÏßÄÏö©)\")\n",
        "\n",
        "        total_imgs += n_imgs\n",
        "        total_lbls += n_lbls\n",
        "        total_bg += n_empty_lbls\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    print(f\"üìà [TOTAL SUMMARY]\")\n",
        "    print(f\"   - Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò : {total_imgs}Ïû•\")\n",
        "    print(f\"   - Background ÎπÑÏú®: {(total_bg/total_imgs)*100:.1f}% ({total_bg}Ïû•)\")\n",
        "    print(f\"   - Ï†ÄÏû• ÏúÑÏπò: {base_dir}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Í≤ÄÏ¶ù Ïã§Ìñâ\n",
        "print_dataset_stats(DEST_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7Qgn94FGOXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRZyju2DPEmD"
      },
      "source": [
        "# Fine-tuning 5Ï∞®\n",
        " - EPOCHS = 50       \n",
        " - BATCH_SIZE = 16\n",
        " - IMG_SIZE = 640\n",
        " - lr0=1e-5,\n",
        " - freeze=10,   \n",
        " - patience=15,\n",
        " - + Ï∫êÍ∏Ä normal Îç∞Ïù¥ÌÑ∞ÏÖã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDvzvk8hNu2h"
      },
      "outputs": [],
      "source": [
        "### trainÏãú 1ÏãúÍ∞Ñ Ï†ïÎèÑ ÏÜåÎ™® Îê©ÎãàÎã§. colabÌôòÍ≤ΩÏóêÏÑú ÏïÑÎûòÎ•º browserÏùò console ÏóêÏÑú Î∂ôÏó¨ ÎÑ£Í∏∞Í∞Ä ÌïÑÏöîÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "### shift+cntr+i Î°ú browser console Ïó¥Í∏∞\n",
        "# https://github.com/chulminkw/DLCV/blob/master/data/util/colab_autoclick.js\n",
        "'''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AI_HUB_IMG_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/images\"\n",
        "AI_HUB_LBL_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/AI_HUB_DAMAGE_DATASET/labels\"\n",
        "\n",
        "# (2) Normal & Background (Source Base)\n",
        "NORMAL_ROOT_BASE = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/RAW\"\n",
        "\n",
        "# 2. Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÄÏû• Í≤ΩÎ°ú (Destination)\n",
        "DEST_DIR = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\""
      ],
      "metadata": {
        "id": "V4VV6P1WX-pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFqmFoV_RpYV"
      },
      "outputs": [],
      "source": [
        "# [Cell 3] Fine-tuning ÏãúÏûë (ÏàòÏ†ïÎê®: Epoch 50Ìöå + Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å Ï†ÄÏû•)\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] Í≤ΩÎ°ú\n",
        "# =========================================================\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION\"\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] ÌååÎùºÎØ∏ÌÑ∞\n",
        "# =========================================================\n",
        "YAML_PATH = os.path.join(DATASET_ROOT, 'data.yaml')\n",
        "MODEL_NAME = 'yolov8x.pt'\n",
        "EPOCHS = 100               # [ÏàòÏ†ï 1] EpochÎ•º 15 -> 50ÏúºÎ°ú Î≥ÄÍ≤Ω\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 640\n",
        "\n",
        "def run_training():\n",
        "    # [ÏàòÏ†ï 2] Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "    SAVE_DIR = os.path.join(PROJECT_ROOT, \"FINE_TUNING_MODEL\")\n",
        "\n",
        "    print(f\"üî• ÌïôÏäµ ÏãúÏûë: {MODEL_NAME} -> Epochs: {EPOCHS}\")\n",
        "    print(f\"   üíæ Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú: {SAVE_DIR}\")\n",
        "\n",
        "    # Î™®Îç∏ Î°úÎìú\n",
        "    model = YOLO(MODEL_NAME)\n",
        "\n",
        "    # ÌïôÏäµ Ïã§Ìñâ\n",
        "    model.train(\n",
        "        data=YAML_PATH,\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMG_SIZE,\n",
        "        batch=BATCH_SIZE,\n",
        "\n",
        "        # [ÏàòÏ†ï 3] project ÌååÎùºÎØ∏ÌÑ∞ Ï∂îÍ∞Ä (Ïó¨Í∏∞Ïóê ÏßÄÏ†ïÌïú Ìè¥Îçî ÏïàÏóê Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•Îê®)\n",
        "        project=SAVE_DIR,\n",
        "        name='yolov8x_fine_tuning_5th', # ÏµúÏ¢Ö Í≤ΩÎ°ú: .../train_results/yolov8x_finetuned_vehicle\n",
        "        exist_ok=True,\n",
        "        optimizer='AdamW',\n",
        "        freeze=10,        # Í∏∞Ï°¥ ÏÑ§Ï†ï Ïú†ÏßÄ\n",
        "        patience=10,\n",
        "        lr0=1e-4,             # Fine-tuningÏù¥ÎØÄÎ°ú ÌïôÏäµÎ•†ÏùÑ Ï°∞Í∏à ÎÇÆÍ≤å ÏÑ§Ï†ï\n",
        "        close_mosaic=10,\n",
        "        verbose=True\n",
        "    )\n",
        "    print(f\"üéâ ÌïôÏäµ ÏôÑÎ£å!\")\n",
        "    print(f\"   Í≤∞Í≥ºÍ∞Ä ÎìúÎùºÏù¥Î∏åÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§: {os.path.join(SAVE_DIR, 'yolov8x_finetuned_vehicle')}\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "run_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkPZ36ctMcR-"
      },
      "source": [
        "## test set ÏÑ±Îä• ÌèâÍ∞Ä(0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTyDZOzVb13L"
      },
      "outputs": [],
      "source": [
        "# [Cell 4] Fine-tuned Model Test Set ÌèâÍ∞Ä (Í≤ΩÎ°ú ÏàòÏ†ïÎê®)\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] Í≤ΩÎ°ú Î∞è ÌååÎùºÎØ∏ÌÑ∞ (User ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÏûêÎèô ÏàòÏ†ïÎê®)\n",
        "# =========================================================\n",
        "# 1. ÌïôÏäµÎêú Î™®Îç∏ Í≤ΩÎ°ú\n",
        "#    (Î∞©Í∏à ÌïôÏäµÌïú Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•Îêú Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å Í≤ΩÎ°ú)\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "# 3. Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú\n",
        "RESULT_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/RESULT\"\n",
        "os.makedirs(RESULT_ROOT, exist_ok=True)\n",
        "\n",
        "CONF_THRESHOLD = 0.25  # Fine-tuning ÌñàÏúºÎØÄÎ°ú ÌëúÏ§Ä ÏûÑÍ≥ÑÍ∞í ÏÇ¨Ïö©\n",
        "\n",
        "def evaluate_finetuned_model():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(f\"‚ùå Î™®Îç∏ ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§: {MODEL_PATH}\")\n",
        "        print(\"   -> ÌïôÏäµÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÏóàÎäîÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üöÄ ÌèâÍ∞Ä ÏãúÏûë...\")\n",
        "    print(f\"   - Î™®Îç∏: {MODEL_PATH}\")\n",
        "    print(f\"   - Îç∞Ïù¥ÌÑ∞: {TEST_IMG_DIR}\")\n",
        "\n",
        "    model = YOLO(MODEL_PATH)\n",
        "\n",
        "    # ÌèâÍ∞Ä ÎåÄÏÉÅ ÌååÏùº Î¶¨Ïä§Ìä∏ÏóÖ\n",
        "    image_files = [f for f in os.listdir(TEST_IMG_DIR) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(f\"‚ùå ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏäµÎãàÎã§. Í≤ΩÎ°úÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî: {TEST_IMG_DIR}\")\n",
        "        return\n",
        "\n",
        "    results_list = []\n",
        "    speed_stats = []\n",
        "\n",
        "    print(f\"   - Ï¥ù ÌèâÍ∞Ä ÎåÄÏÉÅ: {len(image_files)}Ïû•\")\n",
        "\n",
        "    for file in tqdm(image_files, desc=\"Inference\"):\n",
        "        img_path = os.path.join(TEST_IMG_DIR, file)\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, os.path.splitext(file)[0] + \".txt\")\n",
        "\n",
        "        # -----------------------------------------------------\n",
        "        # 1. Ï†ïÎãµ(True Label) ÌôïÏù∏ Î°úÏßÅ\n",
        "        # -----------------------------------------------------\n",
        "        # ÎùºÎ≤® ÌååÏùºÏù¥ ÏûàÍ≥†, ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏßÄ ÏïäÏúºÎ©¥ Vehicle(1)\n",
        "        true_label = 0\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if len(content) > 0:\n",
        "                    true_label = 1\n",
        "\n",
        "        # -----------------------------------------------------\n",
        "        # 2. Î™®Îç∏ Ï∂îÎ°† (Prediction)\n",
        "        # -----------------------------------------------------\n",
        "        results = model(img_path, conf=CONF_THRESHOLD, verbose=False)\n",
        "\n",
        "        # ÏÜçÎèÑ Ï∏°Ï†ï\n",
        "        speed_info = results[0].speed\n",
        "        total_time_ms = speed_info['preprocess'] + speed_info['inference'] + speed_info['postprocess']\n",
        "        speed_stats.append(total_time_ms)\n",
        "\n",
        "        # ÏòàÏ∏° ÎùºÎ≤® Í≤∞Ï†ï (Î∞ïÏä§Í∞Ä ÌïòÎÇòÎùºÎèÑ ÏûàÏúºÎ©¥ Vehicle)\n",
        "        pred_label = 0\n",
        "        for r in results:\n",
        "            if len(r.boxes) > 0:\n",
        "                pred_label = 1\n",
        "                break\n",
        "\n",
        "        # Í≤∞Í≥º Ï†ÄÏû•\n",
        "        results_list.append({\n",
        "            \"filename\": file,\n",
        "            \"true_label\": true_label,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"is_correct\": (true_label == pred_label),\n",
        "            \"full_path\": img_path\n",
        "        })\n",
        "\n",
        "    # Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÌôò\n",
        "    df = pd.DataFrame(results_list)\n",
        "\n",
        "    # =========================================================\n",
        "    # [Î∂ÑÏÑù Í≤∞Í≥º Î¶¨Ìè¨Ìä∏]\n",
        "    # =========================================================\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìä [ÏµúÏ¢Ö Î∂ÑÏÑù Í≤∞Í≥º - Fine-tuned Model]\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # A. Ï†ïÌôïÎèÑ ÌèâÍ∞Ä\n",
        "    acc = accuracy_score(df['true_label'], df['pred_label'])\n",
        "    print(f\"‚úÖ 1. Ï†ïÌôïÎèÑ (Accuracy): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "    # B. ÏÜçÎèÑ ÌèâÍ∞Ä\n",
        "    if speed_stats:\n",
        "        avg_time = np.mean(speed_stats)\n",
        "        min_time = np.min(speed_stats)\n",
        "        max_time = np.max(speed_stats)\n",
        "        fps = 1000 / avg_time\n",
        "\n",
        "        print(f\"\\n‚ö° 2. Ï∂îÎ°† ÏÜçÎèÑ (Inference Speed):\")\n",
        "        print(f\"   - ÌèâÍ∑† ÏÜåÏöî ÏãúÍ∞Ñ : {avg_time:.2f} ms/Ïû•\")\n",
        "        print(f\"   - ÏµúÏÜå ÏÜåÏöî ÏãúÍ∞Ñ : {min_time:.2f} ms\")\n",
        "        print(f\"   - ÏµúÎåÄ ÏÜåÏöî ÏãúÍ∞Ñ : {max_time:.2f} ms\")\n",
        "        print(f\"   - Ï≤òÎ¶¨Îüâ (FPS)   : {fps:.2f} FPS\")\n",
        "\n",
        "    # C. ÏÉÅÏÑ∏ Î∂ÑÎ•ò Î¶¨Ìè¨Ìä∏\n",
        "    print(\"\\nüìù 3. ÏÉÅÏÑ∏ Î∂ÑÎ•ò Î¶¨Ìè¨Ìä∏:\")\n",
        "    print(classification_report(df['true_label'], df['pred_label'], target_names=['Non-Vehicle', 'Vehicle']))\n",
        "\n",
        "    # D. ÌòºÎèô ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    cm = confusion_matrix(df['true_label'], df['pred_label'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Pred: Non-Vehicle', 'Pred: Vehicle'],\n",
        "                yticklabels=['True: Non-Vehicle', 'True: Vehicle'])\n",
        "    plt.title(f'Confusion Matrix\\n(Fine-tuned Result)')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "    # =========================================================\n",
        "    # E. Í≤∞Í≥º Ï†ÄÏû•\n",
        "    # =========================================================\n",
        "    save_filename = f\"inference_finetuned_5th_test_results.csv\"\n",
        "    save_path = os.path.join(RESULT_ROOT, save_filename)\n",
        "\n",
        "    df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nüíæ Ï†ÑÏ≤¥ Ïã§Ìñâ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å!\")\n",
        "    print(f\"   -> ÌååÏùº Í≤ΩÎ°ú: {save_path}\")\n",
        "    print(f\"   -> Ï¥ù Îç∞Ïù¥ÌÑ∞ Ïàò: {len(df)}Í±¥\")\n",
        "\n",
        "    failed_count = len(df[df['is_correct'] == False])\n",
        "    print(f\"   -> (ÏÑ±Í≥µ: {len(df)-failed_count}Í±¥, Ïã§Ìå®: {failed_count}Í±¥)\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "evaluate_finetuned_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2o84YUgVY4l"
      },
      "source": [
        "## Ïò§ÌÉê ÎåÄÏÉÅ ÏãúÍ∞ÅÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAqK2ywsVctO"
      },
      "outputs": [],
      "source": [
        "# [Cell] Ïò§ÌÉê(Failure Case) ÏãúÍ∞ÅÌôî Î∂ÑÏÑù\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "# 3. Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú\n",
        "RESULT_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/RESULT\"\n",
        "CONF_THRESHOLD = 0.25  # Fine-tuning ÌñàÏúºÎØÄÎ°ú ÌëúÏ§Ä ÏûÑÍ≥ÑÍ∞í ÏÇ¨Ïö©\n",
        "\n",
        "\n",
        "def visualize_failures(num_samples=5):\n",
        "    # 1. Ï†ÄÏû•Îêú Í≤∞Í≥º CSV Î°úÎìú\n",
        "    csv_path = os.path.join(RESULT_ROOT, \"inference_finetuned_5th_test_results.csv\")\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"‚ùå Í≤∞Í≥º ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä ÌèâÍ∞Ä ÏΩîÎìúÎ•º Ïã§ÌñâÌïòÏÑ∏Ïöî: {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # 2. Ïã§Ìå® ÏºÄÏù¥Ïä§ ÌïÑÌÑ∞ÎßÅ (is_correct == False)\n",
        "    failures = df[df['is_correct'] == False]\n",
        "\n",
        "    if len(failures) == 0:\n",
        "        print(\"üéâ Ïò§ÌÉê(Ïã§Ìå®) ÏºÄÏù¥Ïä§Í∞Ä ÏóÜÏäµÎãàÎã§! ÏôÑÎ≤ΩÌï©ÎãàÎã§.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç Ï¥ù {len(failures)}Í±¥Ïùò Ïò§ÌÉê Ï§ë ÏÉÅÏúÑ {min(len(failures), num_samples)}Í±¥ÏùÑ ÏãúÍ∞ÅÌôîÌï©ÎãàÎã§...\")\n",
        "\n",
        "    # Î™®Îç∏ Î°úÎìú (Î∞ïÏä§ ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌï¥ ÌïÑÏöî)\n",
        "    model = YOLO(MODEL_PATH)\n",
        "\n",
        "    # ÏÉòÌîåÎßÅ\n",
        "    samples = failures.head(num_samples)\n",
        "\n",
        "    # ÏãúÍ∞ÅÌôî ÏÑ§Ï†ï\n",
        "    plt.figure(figsize=(12, 8 * len(samples)))\n",
        "\n",
        "    for i, (_, row) in enumerate(samples.iterrows()):\n",
        "        img_path = row['full_path']\n",
        "        filename = row['filename']\n",
        "        true_label = row['true_label'] # 1: Vehicle, 0: Non-Vehicle\n",
        "        pred_label = row['pred_label']\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÏóÜÏùå: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # A. Ground Truth Í∑∏Î¶¨Í∏∞ (Green Box)\n",
        "        # -------------------------------------------------\n",
        "        label_file = os.path.splitext(filename)[0] + \".txt\"\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, label_file)\n",
        "\n",
        "        gt_desc = \"Non-Vehicle\"\n",
        "        if true_label == 1:\n",
        "            gt_desc = \"Vehicle\"\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        # YOLO format: class x_center y_center w h\n",
        "                        parts = list(map(float, line.strip().split()))\n",
        "                        if len(parts) >= 5:\n",
        "                            _, bx, by, bw, bh = parts\n",
        "                            # Ï¢åÌëú Î≥ÄÌôò (Normalized -> Pixel)\n",
        "                            x1 = int((bx - bw/2) * w)\n",
        "                            y1 = int((by - bh/2) * h)\n",
        "                            x2 = int((bx + bw/2) * w)\n",
        "                            y2 = int((by + bh/2) * h)\n",
        "\n",
        "                            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 5) # Ï¥àÎ°ùÏÉâ Î∞ïÏä§\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # B. Prediction Í∑∏Î¶¨Í∏∞ (Red Box)\n",
        "        # -------------------------------------------------\n",
        "        # ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌï¥ Ìï¥Îãπ Ïù¥ÎØ∏ÏßÄÎßå Îã§Ïãú Ï∂îÎ°†\n",
        "        results = model(img_path, conf=CONF_THRESHOLD, verbose=False)\n",
        "\n",
        "        pred_desc = \"Non-Vehicle\"\n",
        "        has_pred_box = False\n",
        "\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                has_pred_box = True\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                # ÏòàÏ∏° Î∞ïÏä§ Í∑∏Î¶¨Í∏∞ (Red)\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "                # Ïã†Î¢∞ÎèÑ ÌëúÏãú\n",
        "                label_text = f\"{conf:.2f}\"\n",
        "                t_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "                cv2.rectangle(img, (x1, y1-30), (x1+t_size[0], y1), (255, 0, 0), -1)\n",
        "                cv2.putText(img, label_text, (x1, y1-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "        if has_pred_box:\n",
        "            pred_desc = \"Vehicle\"\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # C. Ï∂úÎ†•\n",
        "        # -------------------------------------------------\n",
        "        plt.subplot(len(samples), 1, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ï†úÎ™© ÏÑ§Ï†ï (Ïã§Ìå® ÏõêÏù∏ Î™ÖÏãú)\n",
        "        fail_type = \"False Negative (ÎØ∏Í≤ÄÏ∂ú)\" if true_label == 1 else \"False Positive (Ïò§Í≤ÄÏ∂ú)\"\n",
        "        title_text = f\"[{i+1}] {filename}\\nType: {fail_type}\\nGT(Green): {gt_desc} vs Pred(Red): {pred_desc}\"\n",
        "\n",
        "        plt.title(title_text, color='red', fontsize=15, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "visualize_failures(130)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_A98s9ALyTT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] Í≤ΩÎ°ú\n",
        "# =========================================================\n",
        "# 1. ÌïôÏäµÎêú ÏµúÏ†Å Î™®Îç∏ Í≤ΩÎ°ú (ÌôïÏù∏ ÌïÑÏöî)\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "def visualize_comparison(num_samples=5):\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(\"‚ùå ÌïôÏäµÎêú Î™®Îç∏ ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "        return\n",
        "\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    files = [f for f in os.listdir(TEST_IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    samples = files[:num_samples]\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * num_samples))\n",
        "\n",
        "    for i, file in enumerate(samples):\n",
        "        img_path = os.path.join(TEST_IMG_DIR, file)\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, os.path.splitext(file)[0] + \".txt\")\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 1. Ground Truth (Ï¥àÎ°ùÏÉâ) Í∑∏Î¶¨Í∏∞\n",
        "        # -------------------------------------------------\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "                    # YOLO xywhn -> pixel xymn (Ï¢åÏÉÅÎã®)\n",
        "                    x1 = int((x - bw / 2) * w)\n",
        "                    y1 = int((y - bh / 2) * h)\n",
        "                    x2 = int((x + bw / 2) * w)\n",
        "                    y2 = int((y + bh / 2) * h)\n",
        "\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3) # Green\n",
        "                    cv2.putText(img, \"GT\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 2. Prediction (Îπ®Í∞ÑÏÉâ) Í∑∏Î¶¨Í∏∞\n",
        "        # -------------------------------------------------\n",
        "        results = model(img_path, conf=0.1, verbose=False) # Threshold ÎÇÆÍ≤å ÏÑ§Ï†ï\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3) # Red\n",
        "                cv2.putText(img, f\"Pred {conf:.2f}\", (x1, y2+30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "        # Ï∂úÎ†•\n",
        "        plt.subplot(num_samples, 1, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Sample: {file} (Green: GT, Red: Prediction)\", fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63H5Q1U4dtAE"
      },
      "outputs": [],
      "source": [
        "# Ïã§Ìñâ\n",
        "visualize_comparison(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnXGTloPjwXK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJcS6Vun3tPg"
      },
      "source": [
        "## test set ÏÑ±Îä• ÌèâÍ∞Ä(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU74DkBI3tPk"
      },
      "outputs": [],
      "source": [
        "# [Cell 4] Fine-tuned Model Test Set ÌèâÍ∞Ä (Í≤ΩÎ°ú ÏàòÏ†ïÎê®)\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] Í≤ΩÎ°ú Î∞è ÌååÎùºÎØ∏ÌÑ∞ (User ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÏûêÎèô ÏàòÏ†ïÎê®)\n",
        "# =========================================================\n",
        "# 1. ÌïôÏäµÎêú Î™®Îç∏ Í≤ΩÎ°ú\n",
        "#    (Î∞©Í∏à ÌïôÏäµÌïú Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•Îêú Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å Í≤ΩÎ°ú)\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "# 3. Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú\n",
        "RESULT_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/RESULT\"\n",
        "os.makedirs(RESULT_ROOT, exist_ok=True)\n",
        "\n",
        "CONF_THRESHOLD = 0.1  # Fine-tuning ÌñàÏúºÎØÄÎ°ú ÌëúÏ§Ä ÏûÑÍ≥ÑÍ∞í ÏÇ¨Ïö©\n",
        "\n",
        "def evaluate_finetuned_model():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(f\"‚ùå Î™®Îç∏ ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§: {MODEL_PATH}\")\n",
        "        print(\"   -> ÌïôÏäµÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÏóàÎäîÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üöÄ ÌèâÍ∞Ä ÏãúÏûë...\")\n",
        "    print(f\"   - Î™®Îç∏: {MODEL_PATH}\")\n",
        "    print(f\"   - Îç∞Ïù¥ÌÑ∞: {TEST_IMG_DIR}\")\n",
        "\n",
        "    model = YOLO(MODEL_PATH)\n",
        "\n",
        "    # ÌèâÍ∞Ä ÎåÄÏÉÅ ÌååÏùº Î¶¨Ïä§Ìä∏ÏóÖ\n",
        "    image_files = [f for f in os.listdir(TEST_IMG_DIR) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        print(f\"‚ùå ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏäµÎãàÎã§. Í≤ΩÎ°úÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî: {TEST_IMG_DIR}\")\n",
        "        return\n",
        "\n",
        "    results_list = []\n",
        "    speed_stats = []\n",
        "\n",
        "    print(f\"   - Ï¥ù ÌèâÍ∞Ä ÎåÄÏÉÅ: {len(image_files)}Ïû•\")\n",
        "\n",
        "    for file in tqdm(image_files, desc=\"Inference\"):\n",
        "        img_path = os.path.join(TEST_IMG_DIR, file)\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, os.path.splitext(file)[0] + \".txt\")\n",
        "\n",
        "        # -----------------------------------------------------\n",
        "        # 1. Ï†ïÎãµ(True Label) ÌôïÏù∏ Î°úÏßÅ\n",
        "        # -----------------------------------------------------\n",
        "        # ÎùºÎ≤® ÌååÏùºÏù¥ ÏûàÍ≥†, ÎÇ¥Ïö©Ïù¥ ÎπÑÏñ¥ÏûàÏßÄ ÏïäÏúºÎ©¥ Vehicle(1)\n",
        "        true_label = 0\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if len(content) > 0:\n",
        "                    true_label = 1\n",
        "\n",
        "        # -----------------------------------------------------\n",
        "        # 2. Î™®Îç∏ Ï∂îÎ°† (Prediction)\n",
        "        # -----------------------------------------------------\n",
        "        results = model(img_path, conf=CONF_THRESHOLD, verbose=False)\n",
        "\n",
        "        # ÏÜçÎèÑ Ï∏°Ï†ï\n",
        "        speed_info = results[0].speed\n",
        "        total_time_ms = speed_info['preprocess'] + speed_info['inference'] + speed_info['postprocess']\n",
        "        speed_stats.append(total_time_ms)\n",
        "\n",
        "        # ÏòàÏ∏° ÎùºÎ≤® Í≤∞Ï†ï (Î∞ïÏä§Í∞Ä ÌïòÎÇòÎùºÎèÑ ÏûàÏúºÎ©¥ Vehicle)\n",
        "        pred_label = 0\n",
        "        for r in results:\n",
        "            if len(r.boxes) > 0:\n",
        "                pred_label = 1\n",
        "                break\n",
        "\n",
        "        # Í≤∞Í≥º Ï†ÄÏû•\n",
        "        results_list.append({\n",
        "            \"filename\": file,\n",
        "            \"true_label\": true_label,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"is_correct\": (true_label == pred_label),\n",
        "            \"full_path\": img_path\n",
        "        })\n",
        "\n",
        "    # Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥ÄÌôò\n",
        "    df = pd.DataFrame(results_list)\n",
        "\n",
        "    # =========================================================\n",
        "    # [Î∂ÑÏÑù Í≤∞Í≥º Î¶¨Ìè¨Ìä∏]\n",
        "    # =========================================================\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìä [ÏµúÏ¢Ö Î∂ÑÏÑù Í≤∞Í≥º - Fine-tuned Model]\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # A. Ï†ïÌôïÎèÑ ÌèâÍ∞Ä\n",
        "    acc = accuracy_score(df['true_label'], df['pred_label'])\n",
        "    print(f\"‚úÖ 1. Ï†ïÌôïÎèÑ (Accuracy): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "    # B. ÏÜçÎèÑ ÌèâÍ∞Ä\n",
        "    if speed_stats:\n",
        "        avg_time = np.mean(speed_stats)\n",
        "        min_time = np.min(speed_stats)\n",
        "        max_time = np.max(speed_stats)\n",
        "        fps = 1000 / avg_time\n",
        "\n",
        "        print(f\"\\n‚ö° 2. Ï∂îÎ°† ÏÜçÎèÑ (Inference Speed):\")\n",
        "        print(f\"   - ÌèâÍ∑† ÏÜåÏöî ÏãúÍ∞Ñ : {avg_time:.2f} ms/Ïû•\")\n",
        "        print(f\"   - ÏµúÏÜå ÏÜåÏöî ÏãúÍ∞Ñ : {min_time:.2f} ms\")\n",
        "        print(f\"   - ÏµúÎåÄ ÏÜåÏöî ÏãúÍ∞Ñ : {max_time:.2f} ms\")\n",
        "        print(f\"   - Ï≤òÎ¶¨Îüâ (FPS)   : {fps:.2f} FPS\")\n",
        "\n",
        "    # C. ÏÉÅÏÑ∏ Î∂ÑÎ•ò Î¶¨Ìè¨Ìä∏\n",
        "    print(\"\\nüìù 3. ÏÉÅÏÑ∏ Î∂ÑÎ•ò Î¶¨Ìè¨Ìä∏:\")\n",
        "    print(classification_report(df['true_label'], df['pred_label'], target_names=['Non-Vehicle', 'Vehicle']))\n",
        "\n",
        "    # D. ÌòºÎèô ÌñâÎ†¨ ÏãúÍ∞ÅÌôî\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    cm = confusion_matrix(df['true_label'], df['pred_label'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Pred: Non-Vehicle', 'Pred: Vehicle'],\n",
        "                yticklabels=['True: Non-Vehicle', 'True: Vehicle'])\n",
        "    plt.title(f'Confusion Matrix\\n(Fine-tuned Result)')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "    # =========================================================\n",
        "    # E. Í≤∞Í≥º Ï†ÄÏû•\n",
        "    # =========================================================\n",
        "    save_filename = f\"inference_finetuned_5th_test_results_conf01.csv\"\n",
        "    save_path = os.path.join(RESULT_ROOT, save_filename)\n",
        "\n",
        "    df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"\\nüíæ Ï†ÑÏ≤¥ Ïã§Ìñâ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å!\")\n",
        "    print(f\"   -> ÌååÏùº Í≤ΩÎ°ú: {save_path}\")\n",
        "    print(f\"   -> Ï¥ù Îç∞Ïù¥ÌÑ∞ Ïàò: {len(df)}Í±¥\")\n",
        "\n",
        "    failed_count = len(df[df['is_correct'] == False])\n",
        "    print(f\"   -> (ÏÑ±Í≥µ: {len(df)-failed_count}Í±¥, Ïã§Ìå®: {failed_count}Í±¥)\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "evaluate_finetuned_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvirgZYI3tPl"
      },
      "source": [
        "## Ïò§ÌÉê ÎåÄÏÉÅ ÏãúÍ∞ÅÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzZ1VayG3tPl"
      },
      "outputs": [],
      "source": [
        "# [Cell] Ïò§ÌÉê(Failure Case) ÏãúÍ∞ÅÌôî Î∂ÑÏÑù\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "# 3. Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú\n",
        "RESULT_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/RESULT\"\n",
        "CONF_THRESHOLD = 0.25  # Fine-tuning ÌñàÏúºÎØÄÎ°ú ÌëúÏ§Ä ÏûÑÍ≥ÑÍ∞í ÏÇ¨Ïö©\n",
        "\n",
        "\n",
        "def visualize_failures(num_samples=5):\n",
        "    # 1. Ï†ÄÏû•Îêú Í≤∞Í≥º CSV Î°úÎìú\n",
        "    csv_path = os.path.join(RESULT_ROOT, \"inference_finetuned_5th_test_results_conf01.csv\")\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"‚ùå Í≤∞Í≥º ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä ÌèâÍ∞Ä ÏΩîÎìúÎ•º Ïã§ÌñâÌïòÏÑ∏Ïöî: {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # 2. Ïã§Ìå® ÏºÄÏù¥Ïä§ ÌïÑÌÑ∞ÎßÅ (is_correct == False)\n",
        "    failures = df[df['is_correct'] == False]\n",
        "\n",
        "    if len(failures) == 0:\n",
        "        print(\"üéâ Ïò§ÌÉê(Ïã§Ìå®) ÏºÄÏù¥Ïä§Í∞Ä ÏóÜÏäµÎãàÎã§! ÏôÑÎ≤ΩÌï©ÎãàÎã§.\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç Ï¥ù {len(failures)}Í±¥Ïùò Ïò§ÌÉê Ï§ë ÏÉÅÏúÑ {min(len(failures), num_samples)}Í±¥ÏùÑ ÏãúÍ∞ÅÌôîÌï©ÎãàÎã§...\")\n",
        "\n",
        "    # Î™®Îç∏ Î°úÎìú (Î∞ïÏä§ ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌï¥ ÌïÑÏöî)\n",
        "    model = YOLO(MODEL_PATH)\n",
        "\n",
        "    # ÏÉòÌîåÎßÅ\n",
        "    samples = failures.head(num_samples)\n",
        "\n",
        "    # ÏãúÍ∞ÅÌôî ÏÑ§Ï†ï\n",
        "    plt.figure(figsize=(12, 8 * len(samples)))\n",
        "\n",
        "    for i, (_, row) in enumerate(samples.iterrows()):\n",
        "        img_path = row['full_path']\n",
        "        filename = row['filename']\n",
        "        true_label = row['true_label'] # 1: Vehicle, 0: Non-Vehicle\n",
        "        pred_label = row['pred_label']\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÏóÜÏùå: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # A. Ground Truth Í∑∏Î¶¨Í∏∞ (Green Box)\n",
        "        # -------------------------------------------------\n",
        "        label_file = os.path.splitext(filename)[0] + \".txt\"\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, label_file)\n",
        "\n",
        "        gt_desc = \"Non-Vehicle\"\n",
        "        if true_label == 1:\n",
        "            gt_desc = \"Vehicle\"\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        # YOLO format: class x_center y_center w h\n",
        "                        parts = list(map(float, line.strip().split()))\n",
        "                        if len(parts) >= 5:\n",
        "                            _, bx, by, bw, bh = parts\n",
        "                            # Ï¢åÌëú Î≥ÄÌôò (Normalized -> Pixel)\n",
        "                            x1 = int((bx - bw/2) * w)\n",
        "                            y1 = int((by - bh/2) * h)\n",
        "                            x2 = int((bx + bw/2) * w)\n",
        "                            y2 = int((by + bh/2) * h)\n",
        "\n",
        "                            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 5) # Ï¥àÎ°ùÏÉâ Î∞ïÏä§\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # B. Prediction Í∑∏Î¶¨Í∏∞ (Red Box)\n",
        "        # -------------------------------------------------\n",
        "        # ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌï¥ Ìï¥Îãπ Ïù¥ÎØ∏ÏßÄÎßå Îã§Ïãú Ï∂îÎ°†\n",
        "        results = model(img_path, conf=CONF_THRESHOLD, verbose=False)\n",
        "\n",
        "        pred_desc = \"Non-Vehicle\"\n",
        "        has_pred_box = False\n",
        "\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                has_pred_box = True\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                # ÏòàÏ∏° Î∞ïÏä§ Í∑∏Î¶¨Í∏∞ (Red)\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "                # Ïã†Î¢∞ÎèÑ ÌëúÏãú\n",
        "                label_text = f\"{conf:.2f}\"\n",
        "                t_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "                cv2.rectangle(img, (x1, y1-30), (x1+t_size[0], y1), (255, 0, 0), -1)\n",
        "                cv2.putText(img, label_text, (x1, y1-5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "        if has_pred_box:\n",
        "            pred_desc = \"Vehicle\"\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # C. Ï∂úÎ†•\n",
        "        # -------------------------------------------------\n",
        "        plt.subplot(len(samples), 1, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ï†úÎ™© ÏÑ§Ï†ï (Ïã§Ìå® ÏõêÏù∏ Î™ÖÏãú)\n",
        "        fail_type = \"False Negative (ÎØ∏Í≤ÄÏ∂ú)\" if true_label == 1 else \"False Positive (Ïò§Í≤ÄÏ∂ú)\"\n",
        "        title_text = f\"[{i+1}] {filename}\\nType: {fail_type}\\nGT(Green): {gt_desc} vs Pred(Red): {pred_desc}\"\n",
        "\n",
        "        plt.title(title_text, color='red', fontsize=15, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "visualize_failures(130)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uYWOFCX3tPl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# =========================================================\n",
        "# [ÏÑ§Ï†ï] Í≤ΩÎ°ú\n",
        "# =========================================================\n",
        "# 1. ÌïôÏäµÎêú ÏµúÏ†Å Î™®Îç∏ Í≤ΩÎ°ú (ÌôïÏù∏ ÌïÑÏöî)\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/DATA/CAR_DETECTION_AIHUB_KAGGLE\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/03. HDMF/(pre_study)2026_HDMF_AUTO_SPOKE/SUBJECT/WEEK1_CAR_DETECTION/FINE_TUNING_MODEL/yolov8x_fine_tuning_5th/weights/best.pt\"\n",
        "\n",
        "# 2. ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú (Hybrid_Split_721 Ìè¥Îçî ÎÇ¥Ïùò test Ìè¥Îçî)\n",
        "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"images/test\")\n",
        "TEST_LABEL_DIR = os.path.join(DATASET_ROOT, \"labels/test\")\n",
        "\n",
        "def visualize_comparison(num_samples=5):\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(\"‚ùå ÌïôÏäµÎêú Î™®Îç∏ ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "        return\n",
        "\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    files = [f for f in os.listdir(TEST_IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "    random.shuffle(files)\n",
        "\n",
        "    samples = files[:num_samples]\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * num_samples))\n",
        "\n",
        "    for i, file in enumerate(samples):\n",
        "        img_path = os.path.join(TEST_IMG_DIR, file)\n",
        "        label_path = os.path.join(TEST_LABEL_DIR, os.path.splitext(file)[0] + \".txt\")\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 1. Ground Truth (Ï¥àÎ°ùÏÉâ) Í∑∏Î¶¨Í∏∞\n",
        "        # -------------------------------------------------\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "                    # YOLO xywhn -> pixel xymn (Ï¢åÏÉÅÎã®)\n",
        "                    x1 = int((x - bw / 2) * w)\n",
        "                    y1 = int((y - bh / 2) * h)\n",
        "                    x2 = int((x + bw / 2) * w)\n",
        "                    y2 = int((y + bh / 2) * h)\n",
        "\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3) # Green\n",
        "                    cv2.putText(img, \"GT\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 2. Prediction (Îπ®Í∞ÑÏÉâ) Í∑∏Î¶¨Í∏∞\n",
        "        # -------------------------------------------------\n",
        "        results = model(img_path, conf=0.1, verbose=False) # Threshold ÎÇÆÍ≤å ÏÑ§Ï†ï\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3) # Red\n",
        "                cv2.putText(img, f\"Pred {conf:.2f}\", (x1, y2+30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "        # Ï∂úÎ†•\n",
        "        plt.subplot(num_samples, 1, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Sample: {file} (Green: GT, Red: Prediction)\", fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïã§Ìñâ\n",
        "visualize_comparison(1)"
      ],
      "metadata": {
        "id": "Xk7WIwrnq3r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DqW0MfsX5uBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llMMEkTV5tzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0CiRF1D5thN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}