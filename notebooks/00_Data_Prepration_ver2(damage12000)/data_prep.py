import os
import json
import shutil
import glob
import random
from tqdm import tqdm
from pathlib import Path

# ==============================================================================
# âš™ï¸ [ì„¤ì •] ì‚¬ìš©ì ë¡œì»¬ ê²½ë¡œ ì„¤ì •
# ==============================================================================

# 1. AI-Hub ì›ë³¸ ë°ì´í„° ê²½ë¡œ (ì‚¬ìš©ìê°€ ì œê³µí•œ ê²½ë¡œ)
# (ê²½ë¡œì— í•œê¸€ì´ ì—†ì–´ì„œ ë¬¸ì œ ì—†ìœ¼ë‚˜, ì—­ìŠ¬ë˜ì‹œ \ ëŒ€ì‹  / ë˜ëŠ” r"" ì‚¬ìš© ê¶Œì¥)
PATHS = {
    "train_images": r"C:\Users\strin\Downloads\AIHUB\DATA\1_Training\1_IMAGES\TS_damage\train",
    "train_labels": r"C:\Users\strin\Downloads\AIHUB\DATA\1_Training\2_LABLES\TL_damage\damage",
    "valid_images": r"C:\Users\strin\Downloads\AIHUB\DATA\2_Validation\1_IMAGES\VS_damage\valid",
    "valid_labels": r"C:\Users\strin\Downloads\AIHUB\DATA\2_Validation\2_LABLES\VL_damage\damage"
}

# 2. ê²°ê³¼ ë°ì´í„°ì…‹ì´ ì €ì¥ë  ê²½ë¡œ (ì´ í´ë”ë¥¼ ë‚˜ì¤‘ì— ì••ì¶•í•´ì„œ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì˜¬ë¦¼)
OUTPUT_DIR = r"C:\Users\strin\Downloads\AI_HUB_DAMAGE_DATASET"

# 3. ëª©í‘œ ìˆ˜ëŸ‰ ì„¤ì • (í´ë˜ìŠ¤ë³„ ë°¸ëŸ°ì‹±)
# Scratched, Separated, Breakage, Crushed ê°ê° ì•„ë˜ ìˆ˜ëŸ‰ë§Œí¼ ë½‘ìŒ
TARGET_COUNTS = {
    "train": 2500,  # í´ë˜ìŠ¤ë‹¹ 2500ì¥ x 4 = 10,000ì¥
    "val": 500      # í´ë˜ìŠ¤ë‹¹ 500ì¥ x 4 = 2,000ì¥
}

# 4. í´ë˜ìŠ¤ ë§¤í•‘ (Text -> ID)
# JSONì˜ "damage" í•„ë“œ ê°’ê³¼ ë§¤ì¹­
CLASS_MAP = {
    "Scratched": 0,
    "Separated": 1,
    "Breakage": 2,
    "Crushed": 3,
    "Dent": 3,      # í˜¹ì‹œ "Dent"ë¡œ í‘œê¸°ëœ ë°ì´í„°ê°€ ìˆë‹¤ë©´ Crushedë¡œ í†µí•©
    "Dented": 3     # ì˜ˆì™¸ ì²˜ë¦¬
}

# ì—­ë§¤í•‘ (ì¶œë ¥ í™•ì¸ìš©)
ID_TO_TEXT = {v: k for k, v in CLASS_MAP.items() if k not in ["Dent", "Dented"]}

# ==============================================================================

def convert_bbox(box, img_w, img_h):
    """[x, y, w, h] -> YOLO [cx, cy, w, h] ì •ê·œí™”"""
    x, y, w, h = box
    cx = (x + w / 2) / img_w
    cy = (y + h / 2) / img_h
    nw = w / img_w
    nh = h / img_h
    return cx, cy, nw, nh

def collect_json_files():
    """Train/Val ë¼ë²¨ í´ë”ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘"""
    print("ğŸ” ë°ì´í„° ìŠ¤ìº” ì¤‘...")
    
    # ì†ŒìŠ¤ë³„ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    file_list = []
    
    # 1. Training Labels
    t_labels = glob.glob(os.path.join(PATHS["train_labels"], "*.json"))
    for json_path in t_labels:
        file_list.append({"path": json_path, "type": "train", "img_root": PATHS["train_images"]})
        
    # 2. Validation Labels
    v_labels = glob.glob(os.path.join(PATHS["valid_labels"], "*.json"))
    for json_path in v_labels:
        file_list.append({"path": json_path, "type": "valid", "img_root": PATHS["valid_images"]})
        
    # ì „ì²´ ì„ê¸° (Train í´ë”ì— ìˆëŠ” ê²ƒë„ Validationìš©ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆê³  ê·¸ ë°˜ëŒ€ë„ ê°€ëŠ¥í•˜ë„ë¡ í’€ë§)
    # í•˜ì§€ë§Œ ì›ë³¸ ë°ì´í„°ì˜ Train/Val êµ¬ë¶„ì„ ì¡´ì¤‘í•˜ë ¤ë©´ ìœ„ ë¡œì§ì„ ë”°ë¥´ë˜, 
    # ì—¬ê¸°ì„œëŠ” 'ê· ë“± ì¶”ì¶œ'ì´ í•µì‹¬ì´ë¯€ë¡œ ì „ì²´ë¥¼ ì„ì–´ì„œ ì¬ë¶„ë°°í•˜ëŠ” ê²ƒì´ ë°¸ëŸ°ì‹±ì— ë” ìœ ë¦¬í•©ë‹ˆë‹¤.
    random.shuffle(file_list)
    print(f"ğŸ‘‰ ì´ {len(file_list)}ê°œì˜ ë¼ë²¨ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return file_list

def create_dataset():
    # ì¶œë ¥ í´ë” ì´ˆê¸°í™”
    if os.path.exists(OUTPUT_DIR):
        print(f"âš ï¸ ê¸°ì¡´ í´ë”ê°€ ì¡´ì¬í•©ë‹ˆë‹¤: {OUTPUT_DIR}")
    
    for split in ['train', 'val']:
        os.makedirs(os.path.join(OUTPUT_DIR, 'images', split), exist_ok=True)
        os.makedirs(os.path.join(OUTPUT_DIR, 'labels', split), exist_ok=True)

    json_files = collect_json_files()
    
    # ì¹´ìš´í„° ì´ˆê¸°í™”
    counts = {
        "train": {0: 0, 1: 0, 2: 0, 3: 0},
        "val": {0: 0, 1: 0, 2: 0, 3: 0}
    }
    
    # ì§„í–‰ë¥  í‘œì‹œ ë°”
    pbar = tqdm(total=len(json_files))
    
    for item in json_files:
        pbar.update(1)
        json_path = item["path"]
        img_root_dir = item["img_root"]
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # --- JSON íŒŒì‹± (ì œê³µí•´ì£¼ì‹  ìƒ˜í”Œ ê¸°ì¤€) ---
            
            # 1. ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
            # ìƒ˜í”Œ: "images": {"id": 1, "width": 800, ...} (Dict í˜•íƒœ)
            img_info = data.get('images', {})
            if isinstance(img_info, list): # í˜¹ì‹œ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ëŒ€ë¹„
                img_info = img_info[0]
                
            file_name = img_info.get('file_name')
            img_w = img_info.get('width')
            img_h = img_info.get('height')
            
            if not file_name or not img_w or not img_h:
                continue # ì •ë³´ ë¶€ì¡± ì‹œ ìŠ¤í‚µ

            # 2. ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            src_img_path = os.path.join(img_root_dir, file_name)
            if not os.path.exists(src_img_path):
                # íŒŒì¼ëª…ì´ ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„ (í™•ì¥ì ë“±)
                base = os.path.splitext(file_name)[0]
                candidates = glob.glob(os.path.join(img_root_dir, base + ".*"))
                if candidates:
                    src_img_path = candidates[0]
                    file_name = os.path.basename(src_img_path)
                else:
                    continue # ì´ë¯¸ì§€ ì—†ìœ¼ë©´ ìŠ¤í‚µ

            # 3. ì–´ë…¸í…Œì´ì…˜ íŒŒì‹±
            anns = data.get('annotations', [])
            yolo_labels = []
            
            # ì´ ì´ë¯¸ì§€ì˜ ëŒ€í‘œ í´ë˜ìŠ¤ (ì¹´ìš´íŒ…ìš©) - ê°€ì¥ ë§ì´ ë“±ì¥í•œ íŒŒì†ì´ë‚˜ ì²« ë²ˆì§¸ íŒŒì†
            target_cls = -1 
            
            for ann in anns:
                damage_type = ann.get('damage', '')
                bbox = ann.get('bbox') # [x, y, w, h]
                
                if damage_type in CLASS_MAP and bbox:
                    cls_id = CLASS_MAP[damage_type]
                    cx, cy, w, h = convert_bbox(bbox, img_w, img_h)
                    
                    # YOLO ë¼ë²¨ í¬ë§·: class x y w h
                    yolo_labels.append(f"{cls_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}")
                    
                    # ì¹´ìš´íŒ… ë¡œì§: í˜„ì¬ ë¶€ì¡±í•œ í´ë˜ìŠ¤ ìš°ì„  ì±„ì›€
                    if target_cls == -1:
                        target_cls = cls_id
            
            if not yolo_labels or target_cls == -1:
                continue # ìœ íš¨í•œ ë¼ë²¨ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ

            # 4. Train/Val ë°°ë¶„ ë¡œì§
            # í˜„ì¬ ì´ ì´ë¯¸ì§€ê°€ ê°€ì§„ í´ë˜ìŠ¤ê°€ Train ëª©í‘œë¥¼ ëª» ì±„ì› ìœ¼ë©´ Trainìœ¼ë¡œ,
            # Trainì€ ì°¼ëŠ”ë° Valì´ ë¹„ì—ˆìœ¼ë©´ Valë¡œ.
            split = None
            
            if counts['train'][target_cls] < TARGET_COUNTS['train']:
                split = 'train'
            elif counts['val'][target_cls] < TARGET_COUNTS['val']:
                split = 'val'
            
            if split is None:
                continue # ì´ë¯¸ ëª©í‘œ ìˆ˜ëŸ‰ì„ ì±„ìš´ í´ë˜ìŠ¤ë©´ íŒ¨ìŠ¤

            # 5. íŒŒì¼ ë³µì‚¬ ë° ë¼ë²¨ ì €ì¥
            # ì´ë¯¸ì§€ ë³µì‚¬
            dst_img_path = os.path.join(OUTPUT_DIR, 'images', split, file_name)
            shutil.copy2(src_img_path, dst_img_path)
            
            # ë¼ë²¨ ì €ì¥
            txt_name = os.path.splitext(file_name)[0] + ".txt"
            dst_txt_path = os.path.join(OUTPUT_DIR, 'labels', split, txt_name)
            with open(dst_txt_path, 'w', encoding='utf-8') as f_out:
                f_out.write("\n".join(yolo_labels))
                
            counts[split][target_cls] += 1
            
            # ì¡°ê¸° ì¢…ë£Œ ì²´í¬ (ëª¨ë“  í´ë˜ìŠ¤ ëª©í‘œ ë‹¬ì„± ì‹œ)
            total_goal = (TARGET_COUNTS['train'] + TARGET_COUNTS['val']) * 4
            current_total = sum(sum(c.values()) for c in counts.values())
            
            if current_total >= total_goal:
                # í•˜ì§€ë§Œ ì •í™•í•œ í´ë˜ìŠ¤ë³„ ë°¸ëŸ°ì‹±ì„ ìœ„í•´ ë£¨í”„ë¥¼ ë°”ë¡œ ëŠê¸°ë³´ë‹¤, 
                # ìœ„ split is None ì¡°ê±´ì— ì˜í•´ ìì—°ìŠ¤ëŸ½ê²Œ í•„í„°ë§ë˜ë„ë¡ ë‘ 
                pass

        except Exception as e:
            # print(f"ì—ëŸ¬ ë°œìƒ {json_path}: {e}")
            continue
            
    pbar.close()
    
    print("\n" + "="*50)
    print("ğŸ‰ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}")
    print("="*50)
    print("ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:")
    for split in ['train', 'val']:
        print(f"\n[{split.upper()}]")
        for cls_id, count in counts[split].items():
            cls_name = ID_TO_TEXT.get(cls_id, f"Class {cls_id}")
            print(f"  - {cls_name}: {count}ì¥")

if __name__ == "__main__":
    create_dataset()